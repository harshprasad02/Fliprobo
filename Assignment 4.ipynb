{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the mentioned details.\n",
    "ranks = []\n",
    "names = []\n",
    "uploders = []\n",
    "views = []\n",
    "dates = []\n",
    "#first extracting ranks from the page\n",
    "rank = driver.find_elements_by_xpath(\"//table[@class = 'wikitable sortable jquery-tablesorter'][1]//tbody[1]//tr//td[@align = 'center'][1]\")\n",
    "for i in rank:\n",
    "    ranks.append(i.text)\n",
    "#extracting name from the page\n",
    "name = driver.find_elements_by_xpath(\"//table[@class = 'wikitable sortable jquery-tablesorter'][1]//tbody[1]//tr//td[2]\")\n",
    "for i in name:\n",
    "    names.append(i.text)\n",
    "#extracting uploaders detail from the page\n",
    "uploder = driver.find_elements_by_xpath(\"//table[@class = 'wikitable sortable jquery-tablesorter'][1]//tbody[1]//tr//td[3]\")\n",
    "for i in uploder:\n",
    "    uploders.append(i.text)\n",
    "#extracting views from the page\n",
    "view = driver.find_elements_by_xpath(\"//table[@class = 'wikitable sortable jquery-tablesorter'][1]//tbody[1]//tr//td[4]\")\n",
    "for i in view:\n",
    "    views.append(i.text)\n",
    "#extracting uploading dates from the page\n",
    "date = driver.find_elements_by_xpath(\"//table[@class = 'wikitable sortable jquery-tablesorter'][1]//tbody[1]//tr//td[5]\")\n",
    "for i in date:\n",
    "    dates.append(i.text)\n",
    "#creating data frame\n",
    "Youtube_views = pd.DataFrame({\"Rank\" : ranks, \"Name of the youtube Video\" : names,\"Artist\": uploders,\"Views (in Billions)\":views,\n",
    "                             \"Upload Date\":dates})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name of the youtube Video</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.71</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.38</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.41</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.34</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.13</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[31]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.19</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.12</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Bath Song\"[33]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.10</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.08</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.90</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.48</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.44</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Dame Tu Cosita\"[39]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.37</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.36</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.31</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.26</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.08</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.07</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.06</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Wheels on the Bus\"[46]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.05</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lean On\"[47]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.04</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Bailando\"[48]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.04</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Girls Like You\"[49]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.04</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.00</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.92</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.86</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Hello\"[53]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.84</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.84</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Axel F\"[55]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.82</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                        Name of the youtube Video  \\\n",
       "0    1.                           \"Baby Shark Dance\"[22]   \n",
       "1    2.                                  \"Despacito\"[24]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[25]   \n",
       "3    4.                               \"Shape of You\"[26]   \n",
       "4    5.                              \"See You Again\"[27]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "6    7.                                \"Uptown Funk\"[31]   \n",
       "7    8.  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "8    9.                                  \"Bath Song\"[33]   \n",
       "9   10.                              \"Gangnam Style\"[34]   \n",
       "10  11.                \"Phonics Song with Two Words\"[36]   \n",
       "11  12.                                      \"Sugar\"[37]   \n",
       "12  13.                                      \"Sorry\"[38]   \n",
       "13  14.                             \"Dame Tu Cosita\"[39]   \n",
       "14  15.                                       \"Roar\"[40]   \n",
       "15  16.                             \"Counting Stars\"[41]   \n",
       "16  17.                          \"Thinking Out Loud\"[42]   \n",
       "17  18.                                 \"Dark Horse\"[43]   \n",
       "18  19.                                      \"Faded\"[44]   \n",
       "19  20.                               \"Shake It Off\"[45]   \n",
       "20  21.                          \"Wheels on the Bus\"[46]   \n",
       "21  22.                                    \"Lean On\"[47]   \n",
       "22  23.                                   \"Bailando\"[48]   \n",
       "23  24.                             \"Girls Like You\"[49]   \n",
       "24  25.                                 \"Let Her Go\"[50]   \n",
       "25  26.                                   \"Mi Gente\"[51]   \n",
       "26  27.                                    \"Perfect\"[52]   \n",
       "27  28.                                      \"Hello\"[53]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "29  30.                                     \"Axel F\"[55]   \n",
       "\n",
       "                            Artist Views (in Billions)        Upload Date  \n",
       "0   Pinkfong Kids' Songs & Stories                8.71      June 17, 2016  \n",
       "1                       Luis Fonsi                7.38   January 12, 2017  \n",
       "2                      LooLoo Kids                5.41    October 8, 2016  \n",
       "3                       Ed Sheeran                5.34   January 30, 2017  \n",
       "4                      Wiz Khalifa                5.13      April 6, 2015  \n",
       "5                       Get Movies                4.44   January 31, 2012  \n",
       "6                      Mark Ronson                4.19  November 19, 2014  \n",
       "7                      Miroshka TV                4.12  February 27, 2018  \n",
       "8       Cocomelon – Nursery Rhymes                4.10        May 2, 2018  \n",
       "9                              Psy                4.08      July 15, 2012  \n",
       "10                       ChuChu TV                3.90      March 6, 2014  \n",
       "11                        Maroon 5                3.48   January 14, 2015  \n",
       "12                   Justin Bieber                3.44   October 22, 2015  \n",
       "13                       El Chombo                3.37      April 5, 2018  \n",
       "14                      Katy Perry                3.36  September 5, 2013  \n",
       "15                     OneRepublic                3.31       May 31, 2013  \n",
       "16                      Ed Sheeran                3.26    October 7, 2014  \n",
       "17                      Katy Perry                3.08  February 20, 2014  \n",
       "18                     Alan Walker                3.07   December 3, 2015  \n",
       "19                    Taylor Swift                3.06    August 18, 2014  \n",
       "20      Cocomelon – Nursery Rhymes                3.05       May 24, 2018  \n",
       "21                     Major Lazer                3.04     March 22, 2015  \n",
       "22                Enrique Iglesias                3.04     April 11, 2014  \n",
       "23                        Maroon 5                3.04       May 31, 2018  \n",
       "24                       Passenger                3.00      July 25, 2012  \n",
       "25                        J Balvin                2.92      June 29, 2017  \n",
       "26                      Ed Sheeran                2.86   November 9, 2017  \n",
       "27                           Adele                2.84   October 22, 2015  \n",
       "28                         Shakira                2.84       June 4, 2010  \n",
       "29                      Crazy Frog                2.82      June 16, 2009  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url2 = \"https://www.bcci.tv/\"\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting link of the fixture button from the dropdown menu\n",
    "fixture = driver.find_element_by_xpath(\"//div[@class = 'navigation__drop-down drop-down drop-down--reveal-on-hover']//div//ul//li[1]//a\")\n",
    "fixture_link=fixture.get_attribute('href')\n",
    "driver.get(fixture_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>18 JUNE</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                       Series                        Place  \\\n",
       "0       Final  ICC WORLD TEST CHAMPIONSHIP  The Ageas Bowl, Southampton   \n",
       "1    1st Test         ENGLAND V INDIA 2021     Trent Bridge, Nottingham   \n",
       "2    2nd Test         ENGLAND V INDIA 2021               Lord's, London   \n",
       "3    3rd Test         ENGLAND V INDIA 2021            Headingley, Leeds   \n",
       "4    4th Test         ENGLAND V INDIA 2021             The Oval, London   \n",
       "5    5th Test         ENGLAND V INDIA 2021     Old Trafford, Manchester   \n",
       "\n",
       "           Date       Time  \n",
       "0       18 JUNE  15:00 IST  \n",
       "1     04 AUGUST  15:30 IST  \n",
       "2     12 AUGUST  15:30 IST  \n",
       "3     25 AUGUST  15:30 IST  \n",
       "4  02 SEPTEMBER  15:30 IST  \n",
       "5  10 SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating lists of different variables first\n",
    "serieses = []\n",
    "matches = []\n",
    "places = []\n",
    "dates = []\n",
    "months = []\n",
    "fixture = []\n",
    "times = []\n",
    "\n",
    "\n",
    "\n",
    "#extracting web element of series\n",
    "series = driver.find_elements_by_xpath(\"//span[@class = 'u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "for i in series:\n",
    "    serieses.append(i.text)#extracting series from the web element\n",
    "\n",
    "#extracting web element of match    \n",
    "Match_title = driver.find_elements_by_xpath(\"//strong[@class = 'fixture__name fixture__name--with-margin']\")\n",
    "for i in Match_title:\n",
    "    matches.append(i.text) #extracting matches from the web element\n",
    "\n",
    "#extracting web element of place   \n",
    "Place = driver.find_elements_by_xpath(\"//p[@class = 'fixture__additional-info']//span\")\n",
    "for i in Place:\n",
    "    places.append(i.text)#extracting places from the web element\n",
    "\n",
    "#extracting dates web elements\n",
    "date = driver.find_elements_by_xpath(\"//span[@class = 'fixture__date']\")\n",
    "for i in date:\n",
    "    dates.append(i.text)#extracting dates from the web element\n",
    "    \n",
    "#extracting months web elements\n",
    "month = driver.find_elements_by_xpath(\"//span[@class = 'fixture__month']\")\n",
    "for i in month:\n",
    "    months.append(i.text)#extracting months from the web element\n",
    "\n",
    "#since date and month are two different list we'll combine them together and store it in another list \n",
    "\n",
    "\n",
    "for i in range(0,6):\n",
    "    fixture.append(dates[i]+\" \"+months[i])#combining months and dates together.\n",
    "    \n",
    "#extracting times web elements\n",
    "time = driver.find_elements_by_xpath(\"//span[@class = 'fixture__time']\")\n",
    "for i in time:\n",
    "    times.append(i.text)#extracting time from the web elements\n",
    "    \n",
    "    \n",
    "Fixture_international = pd.DataFrame({\"Match Title\": matches,\"Series\": serieses,\"Place\": places,\"Date\": fixture,\"Time\": times})\n",
    "Fixture_international"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Scrape the details of selenium exception from guru99.com.\n",
    "\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_selenium = \"https://www.guru99.com/\"\n",
    "driver.get(url_selenium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we'll get the xpath of the selenium image button present on the web page and the extract link from it.\n",
    "selenium_link = driver.find_element_by_xpath(\"//div[@class = 'canvas-middle']//a\").get_attribute('href')\n",
    "driver.get(selenium_link) #reaching the page through link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this page we'll get the link of the selenium exception handling page\n",
    "selenium_exception_page_link = driver.find_element_by_xpath(\"//table[@class = 'table'][5]//tbody//tr[34]//td[1]//a\").get_attribute('href')\n",
    "driver.get(selenium_exception_page_link) #reaching the exception handling page using the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empt lists of the desired features\n",
    "name_of_exception = []\n",
    "description_of_exception = []\n",
    "\n",
    "#importing name of exceptions using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class = 'table table-striped']//tbody//tr//td[1]\"):\n",
    "        name_of_exception.append(i.text)     #storing name of exceptions in the list\n",
    "except NoSuchElementException:\n",
    "    name_of_exception.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#importing descriptions of exception using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class = 'table table-striped']//tbody//tr//td[2]\"):\n",
    "        description_of_exception.append(i.text)     #storing descritpion of exception in the list\n",
    "except NoSuchElementException:\n",
    "    description_of_exception.append('-')\n",
    "\n",
    "    \n",
    "#since both the lists contains the heading of the table so we'll seperate it from the main content\n",
    "name_of_exception = name_of_exception[1:42] \n",
    "description_of_exception = description_of_exception[1:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of exception</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name of exception  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frames \n",
    "Selenium_exception = pd.DataFrame({\"Name of exception\": name_of_exception , \"Description\" : description_of_exception})\n",
    "Selenium_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP at current price (19-20)\n",
    "\n",
    "D) GSDP at current price (18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_stats = \"http://statisticstimes.com/\"\n",
    "driver.get(url_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the statisticstimes.com we will select india from economy dropdown menu.\n",
    "economy_selector = driver.find_element_by_xpath(\"//div[@class = 'navbar']//div[2]//div[@class = 'dropdown-content']//a[3]\")\n",
    "link_to_india =economy_selector.get_attribute('href')\n",
    "driver.get(link_to_india) #getting to indian statistics page\n",
    "#from indian statistics page we'll go to GDP of Indian states\n",
    "indian_gdp_options = driver.find_element_by_xpath(\"//div[@style ='float:left;background-color:seashell;width:400px;height:800px;']//ul//li[1]//a\")#extracting elemnet of gdp of indian states\n",
    "gdp_of_indian_states_link = indian_gdp_options.get_attribute('href') #extracting the link\n",
    "gdp_of_indian_states_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(gdp_of_indian_states_link) #visting the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists of the the desired features.\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP = []\n",
    "GSDP_18 = []\n",
    "Share = []\n",
    "GDP = []\n",
    "\n",
    "#importing ranks of the states from the elements    \n",
    "try:\n",
    "    Rank1 = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[@class = 'data1']\")#extractiong rank using xpath\n",
    "    for i in Rank1[0:33]:\n",
    "        Rank.append(i.text)    #storing ranks in the Rank list\n",
    "except NoSuchElementException:\n",
    "        Rank.append('-')\n",
    "\n",
    "#importing Name of the states from the elements \n",
    "try:\n",
    "    State1 = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[@class = 'name']\")#extracting States name using xpath\n",
    "    for i in State1[0:33]:\n",
    "        State.append(i.text) #storing States name in the State list\n",
    "except NoSuchElementException:\n",
    "        State.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "#importing GSDP at current price (19-20) from the elements\n",
    "try:\n",
    "    GSDP_1 = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[3]\")#extracting GSDP 19-20 using xpath\n",
    "    for i in GSDP_1[0:33]:\n",
    "        GSDP.append(i.text)     #storing GSDP in the Rank list\n",
    "except NoSuchElementException:\n",
    "    GSDP.append('-')      \n",
    "        \n",
    "        \n",
    "        \n",
    "#importing GSDP at current price (18-19) from the elements\n",
    "try:\n",
    "    GSDP_18s = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[@class = 'data sorting_1']\")#extracting GSDP 18-19 using xpath\n",
    "    for i in GSDP_18s[0:33]:\n",
    "        GSDP_18.append(i.text)     #storing GSDP 18-19 in the Rank list\n",
    "except NoSuchElementException:\n",
    "    GSDP_18.append('-')\n",
    "    \n",
    "    \n",
    "\n",
    "#importing Share of year (18-19) from the elements\n",
    "try:\n",
    "    Share1 = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[5]\")#extracting Share 18-19 using xpath\n",
    "    for i in Share1[0:33]:\n",
    "        Share.append(i.text)     #storing Share in the Rank list\n",
    "except NoSuchElementException:\n",
    "    Share.append('-')\n",
    "\n",
    "\n",
    "#importing GDP of year from the elements\n",
    "try:\n",
    "    GDP1 = driver.find_elements_by_xpath(\"//div[@class = 'dataTables_wrapper']//table[1]//tbody//tr//td[6]\")#extracting GDP using xpath\n",
    "    for i in GDP1[0:33]:\n",
    "        GDP.append(i.text)     #storing GDP in the Rank list\n",
    "except NoSuchElementException:\n",
    "    GDP.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe\n",
    "GDP_Indian_States = pd.DataFrame({\"Rank\" : Rank,\"Name of the State\":State,\"GSDP (Cr INR at Current prices)(19-20)\":GSDP ,\"GSDP (Cr INR at Current prices)(18-19)\" :GSDP_18,\n",
    "                                 \"Share (18-19)\": Share, \"GDP ($billion)\":GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name of the State</th>\n",
       "      <th>GSDP (Cr INR at Current prices)(19-20)</th>\n",
       "      <th>GSDP (Cr INR at Current prices)(18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP ($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Name of the State GSDP (Cr INR at Current prices)(19-20)  \\\n",
       "0     1                Maharashtra                                      -   \n",
       "1     2                 Tamil Nadu                              1,845,853   \n",
       "2     3              Uttar Pradesh                              1,687,818   \n",
       "3     4                    Gujarat                                      -   \n",
       "4     5                  Karnataka                              1,631,977   \n",
       "5     6                West Bengal                              1,253,832   \n",
       "6     7                  Rajasthan                              1,020,989   \n",
       "7     8             Andhra Pradesh                                972,782   \n",
       "8     9                  Telangana                                969,604   \n",
       "9    10             Madhya Pradesh                                906,672   \n",
       "10   11                     Kerala                                      -   \n",
       "11   12                      Delhi                                856,112   \n",
       "12   13                    Haryana                                831,610   \n",
       "13   14                      Bihar                                611,804   \n",
       "14   15                     Punjab                                574,760   \n",
       "15   16                     Odisha                                521,275   \n",
       "16   17                      Assam                                      -   \n",
       "17   18               Chhattisgarh                                329,180   \n",
       "18   19                  Jharkhand                                328,598   \n",
       "19   20                Uttarakhand                                      -   \n",
       "20   21            Jammu & Kashmir                                      -   \n",
       "21   22           Himachal Pradesh                                165,472   \n",
       "22   23                        Goa                                 80,449   \n",
       "23   24                    Tripura                                 55,984   \n",
       "24   25                 Chandigarh                                      -   \n",
       "25   26                 Puducherry                                 38,253   \n",
       "26   27                  Meghalaya                                 36,572   \n",
       "27   28                     Sikkim                                 32,496   \n",
       "28   29                    Manipur                                 31,790   \n",
       "29   30                   Nagaland                                      -   \n",
       "30   31          Arunachal Pradesh                                      -   \n",
       "31   32                    Mizoram                                 26,503   \n",
       "32   33  Andaman & Nicobar Islands                                      -   \n",
       "\n",
       "   GSDP (Cr INR at Current prices)(18-19) Share (18-19) GDP ($billion)  \n",
       "0                               2,632,792        13.94%        399.921  \n",
       "1                               1,630,208         8.63%        247.629  \n",
       "2                               1,584,764         8.39%        240.726  \n",
       "3                               1,502,899         7.96%        228.290  \n",
       "4                               1,493,127         7.91%        226.806  \n",
       "5                               1,089,898         5.77%        165.556  \n",
       "6                                 942,586         4.99%        143.179  \n",
       "7                                 862,957         4.57%        131.083  \n",
       "8                                 861,031         4.56%        130.791  \n",
       "9                                 809,592         4.29%        122.977  \n",
       "10                                781,653         4.14%        118.733  \n",
       "11                                774,870         4.10%        117.703  \n",
       "12                                734,163         3.89%        111.519  \n",
       "13                                530,363         2.81%         80.562  \n",
       "14                                526,376         2.79%         79.957  \n",
       "15                                487,805         2.58%         74.098  \n",
       "16                                315,881         1.67%         47.982  \n",
       "17                                304,063         1.61%         46.187  \n",
       "18                                297,204         1.57%         45.145  \n",
       "19                                245,895         1.30%         37.351  \n",
       "20                                155,956         0.83%         23.690  \n",
       "21                                153,845         0.81%         23.369  \n",
       "22                                 73,170         0.39%         11.115  \n",
       "23                                 49,845         0.26%          7.571  \n",
       "24                                 42,114         0.22%          6.397  \n",
       "25                                 34,433         0.18%          5.230  \n",
       "26                                 33,481         0.18%          5.086  \n",
       "27                                 28,723         0.15%          4.363  \n",
       "28                                 27,870         0.15%          4.233  \n",
       "29                                 27,283         0.14%          4.144  \n",
       "30                                 24,603         0.13%          3.737  \n",
       "31                                 22,287         0.12%          3.385  \n",
       "32                                      -             -              -  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP_Indian_States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_git_hub = \"https://github.com/\"\n",
    "driver.get(url_git_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/trending'"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the web elemnt of extended list\n",
    "extend_list = driver.find_element_by_xpath(\"//button[@class = 'btn-link d-lg-none mt-1 js-details-target']\")\n",
    "extend_list.click()\n",
    "#importing the trending link from the explore dropdown\n",
    "explore_dropdown = driver.find_element_by_xpath(\"//div[@class = 'dropdown-menu flex-auto rounded px-0 pt-2 pb-0 mt-0 pb-4 p-lg-4 position-relative position-lg-absolute left-0 left-lg-n4']//ul[2]//li[3]//a\")\n",
    "\n",
    "trending_link = explore_dropdown.get_attribute('href')\n",
    "trending_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now extracting desired elements from this trending web page\n",
    "driver.get(trending_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists of all the desired features\n",
    "Repository_title = []\n",
    "Repository_description = []\n",
    "Contributors_count = []\n",
    "Language_used = []\n",
    "\n",
    "time.sleep(5)\n",
    "#importing repository title using xpath\n",
    "try:\n",
    "    repository = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "    for i in repository:\n",
    "        Repository_title.append(i.text) #storing repository titles in the list\n",
    "except NoSuchElementException:\n",
    "    Repository_title.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "#importing repository description using xpath\n",
    "try:\n",
    "    description = driver.find_elements_by_xpath(\"//article[@class = 'Box-row']//p[@class = 'col-9 color-text-secondary my-1 pr-4']\")\n",
    "    for i in description:\n",
    "        Repository_description.append(i.text) #storing repository description in the list\n",
    "except NoSuchElementException:\n",
    "    Repository_description.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "#importing Language used using xpath\n",
    "try:\n",
    "    language = driver.find_elements_by_xpath(\"//span[@class = 'd-inline-block ml-0 mr-3']//span[2]\")\n",
    "    for i in language:\n",
    "        Language_used.append(i.text) #storing language of the code in the list\n",
    "except NoSuchElementException:\n",
    "    Language_used.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#for importing the contributors count we'll first extract all the urls of each of the reprository and then extract contributors count from there\n",
    "#extracting urls of reprository\n",
    "urls = []\n",
    "url = driver.find_elements_by_xpath(\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in url:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    \n",
    "#now we'll go inside each reprository using the url and extract contributors coutn from there     \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        contributor_count = driver.find_element_by_xpath(\"//div[@class ='flex-shrink-0 col-12 col-md-3']//div[@class = 'BorderGrid BorderGrid--spacious']//div[4]//div//h2//a//span\").text\n",
    "        Contributors_count.append(contributor_count)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Language Used</th>\n",
       "      <th>Contributors Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>siduck76 / NvChad</td>\n",
       "      <td>beautiful neovim setup configured in lua</td>\n",
       "      <td>Lua</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>star261 / jd</td>\n",
       "      <td>Watchy - An Open Source E-Ink Smartwatch</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqfmi / Watchy</td>\n",
       "      <td>An easier way to build neural search on the cloud</td>\n",
       "      <td>C</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jina-ai / jina</td>\n",
       "      <td>You like pytorch? You like micrograd? You love...</td>\n",
       "      <td>Python</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geohot / tinygrad</td>\n",
       "      <td>Use Turbo in your Ruby on Rails app</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hotwired / turbo-rails</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>Turn (almost) any Python command line program ...</td>\n",
       "      <td>Python</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chriskiehl / Gooey</td>\n",
       "      <td>梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...</td>\n",
       "      <td>C</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>monyhar / monyhar-lite</td>\n",
       "      <td>The official GitHub mirror of the Chromium source</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chromium / chromium</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>C#</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trimstray / the-book-of-secret-knowledge</td>\n",
       "      <td>30 days of JavaScript programming challenge is...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Asabeneh / 30-Days-Of-JavaScript</td>\n",
       "      <td>A long list of (advanced) JavaScript questions...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lydiahallie / javascript-questions</td>\n",
       "      <td>Keeps your screen real-estate clean with refin...</td>\n",
       "      <td>Python</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neon-age / Smart-Inspector</td>\n",
       "      <td>Alibaba Group Unified Form Solution -- Support...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alibaba / formily</td>\n",
       "      <td>PyTorch Tutorial for Deep Learning Researchers</td>\n",
       "      <td>Go</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JDHelloWorld / jd_scripts</td>\n",
       "      <td>The React Framework</td>\n",
       "      <td>Python</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yunjey / pytorch-tutorial</td>\n",
       "      <td>【编程随想】收藏的电子书清单（多个学科，含下载链接）</td>\n",
       "      <td>C</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vercel / next.js</td>\n",
       "      <td>Bee is a Swarm client implemented in Go. It’s ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>320k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>programthink / books</td>\n",
       "      <td>Rich is a Python library for rich text and bea...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ethersphere / bee</td>\n",
       "      <td>An 8-bit minicomputer with a fully custom arch...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>willmcgugan / rich</td>\n",
       "      <td>Official implementation of \"SegFormer: Simple ...</td>\n",
       "      <td>-</td>\n",
       "      <td>3.7k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jdah / jdh-8</td>\n",
       "      <td>An open source remote desktop client software</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NVlabs / SegFormer</td>\n",
       "      <td>Tutorial created by Enyel Sequeira, taught by ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rustdesk / rustdesk</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adrianhajdin / portfolio_website</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository Title  \\\n",
       "0                          siduck76 / NvChad   \n",
       "1                               star261 / jd   \n",
       "2                             sqfmi / Watchy   \n",
       "3                             jina-ai / jina   \n",
       "4                          geohot / tinygrad   \n",
       "5                     hotwired / turbo-rails   \n",
       "6      jwasham / coding-interview-university   \n",
       "7                         chriskiehl / Gooey   \n",
       "8                     monyhar / monyhar-lite   \n",
       "9                        chromium / chromium   \n",
       "10  trimstray / the-book-of-secret-knowledge   \n",
       "11          Asabeneh / 30-Days-Of-JavaScript   \n",
       "12        lydiahallie / javascript-questions   \n",
       "13                neon-age / Smart-Inspector   \n",
       "14                         alibaba / formily   \n",
       "15                 JDHelloWorld / jd_scripts   \n",
       "16                 yunjey / pytorch-tutorial   \n",
       "17                          vercel / next.js   \n",
       "18                      programthink / books   \n",
       "19                         ethersphere / bee   \n",
       "20                        willmcgugan / rich   \n",
       "21                              jdah / jdh-8   \n",
       "22                        NVlabs / SegFormer   \n",
       "23                       rustdesk / rustdesk   \n",
       "24          adrianhajdin / portfolio_website   \n",
       "\n",
       "                               Repository Description Language Used  \\\n",
       "0            beautiful neovim setup configured in lua           Lua   \n",
       "1            Watchy - An Open Source E-Ink Smartwatch    JavaScript   \n",
       "2   An easier way to build neural search on the cloud             C   \n",
       "3   You like pytorch? You like micrograd? You love...        Python   \n",
       "4                 Use Turbo in your Ruby on Rails app        Python   \n",
       "5   A complete computer science study plan to beco...    JavaScript   \n",
       "6   Turn (almost) any Python command line program ...        Python   \n",
       "7   梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...             C   \n",
       "8   The official GitHub mirror of the Chromium source    JavaScript   \n",
       "9   A collection of inspiring lists, manuals, chea...            C#   \n",
       "10  30 days of JavaScript programming challenge is...    TypeScript   \n",
       "11  A long list of (advanced) JavaScript questions...    JavaScript   \n",
       "12  Keeps your screen real-estate clean with refin...        Python   \n",
       "13  Alibaba Group Unified Form Solution -- Support...    JavaScript   \n",
       "14     PyTorch Tutorial for Deep Learning Researchers            Go   \n",
       "15                                The React Framework        Python   \n",
       "16                         【编程随想】收藏的电子书清单（多个学科，含下载链接）             C   \n",
       "17  Bee is a Swarm client implemented in Go. It’s ...        Python   \n",
       "18  Rich is a Python library for rich text and bea...          Rust   \n",
       "19  An 8-bit minicomputer with a fully custom arch...    JavaScript   \n",
       "20  Official implementation of \"SegFormer: Simple ...             -   \n",
       "21      An open source remote desktop client software             -   \n",
       "22  Tutorial created by Enyel Sequeira, taught by ...             -   \n",
       "23                                                  -             -   \n",
       "24                                                  -             -   \n",
       "\n",
       "   Contributors Count  \n",
       "0                   -  \n",
       "1                   2  \n",
       "2                   -  \n",
       "3                  97  \n",
       "4                   1  \n",
       "5                   -  \n",
       "6                      \n",
       "7                 334  \n",
       "8                   -  \n",
       "9                   -  \n",
       "10                     \n",
       "11                  -  \n",
       "12                  -  \n",
       "13                     \n",
       "14                     \n",
       "15                  -  \n",
       "16                  -  \n",
       "17               320k  \n",
       "18                  -  \n",
       "19                 36  \n",
       "20               3.7k  \n",
       "21                  -  \n",
       "22                  -  \n",
       "23                     \n",
       "24                  -  "
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Git_hub_repository = pd.DataFrame({\"Repository Title\": Repository_title,\"Repository Description\" : Repository_description,\n",
    "                                  \"Language Used\": Language_used, \"Contributors Count\" : Contributors_count})\n",
    "Git_hub_repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question number 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_bill = \"https://www.billboard.com/\"\n",
    "driver.get(url_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we'll extract link to hot 100 page\n",
    "hot_100_link = driver.find_element_by_xpath(\"//nav[@class = 'header__subnav bg--light']//ul//li[3]//a\").get_attribute('href')\n",
    "#now we'll get to the desired page using the link\n",
    "driver.get(hot_100_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists of all the desired features\n",
    "song_name = []\n",
    "artist_name = []\n",
    "last_week_rank =[]\n",
    "peak_rank = []\n",
    "weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing song name from the elements\n",
    "try:\n",
    "    song_name1 =driver.find_elements_by_xpath(\"//span[@class = 'chart-element__information__song text--truncate color--primary']\")#extracting song name using xpath\n",
    "    for i in song_name1:\n",
    "        song_name.append(i.text)     #storing songs name in the song name list\n",
    "except NoSuchElementException:\n",
    "    song_name.append('-')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#importing artists name from the elements\n",
    "try:\n",
    "    artist_name1 =driver.find_elements_by_xpath(\"//span[@class = 'chart-element__information__artist text--truncate color--secondary']\")#extracting artist name using xpath\n",
    "    for i in artist_name1:\n",
    "        artist_name.append(i.text)     #storing artists name in the artist name list\n",
    "except NoSuchElementException:\n",
    "    artist_name.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#importing last week from the elements\n",
    "try:\n",
    "    last_week_rank1 =driver.find_elements_by_xpath(\"//div[@class = 'chart-element__meta text--center color--secondary text--last']\")#extracting last week details using xpath\n",
    "    for i in last_week_rank1:\n",
    "        last_week_rank.append(i.text)     #storing last week rank in the last week rank list\n",
    "except NoSuchElementException:\n",
    "    last_week_rank.append('-')\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #importing peak rank  from the elements\n",
    "try:\n",
    "    peak_rank1 =driver.find_elements_by_xpath(\"//div[@class = 'chart-element__meta text--center color--secondary text--peak']\")#extracting peak rank using xpath\n",
    "    for i in peak_rank1:\n",
    "        peak_rank.append(i.text)     #storing peak rank in the peak rank list\n",
    "except NoSuchElementException:\n",
    "    peak_rank.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#importing week on boards from the elements\n",
    "try:\n",
    "    week_on_boards1 =driver.find_elements_by_xpath(\"//div[@class = 'chart-element__meta text--center color--secondary text--week']\")#extracting week on boards using xpath\n",
    "    for i in week_on_boards1:\n",
    "        weeks_on_board.append(i.text)     #storing week on boards in the week on boards list\n",
    "except NoSuchElementException:\n",
    "    weeks_on_board.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song Name  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       Artist Name Last week Rank Peak Rank  \\\n",
       "0                                              BTS              1         1   \n",
       "1                                   Olivia Rodrigo              2         1   \n",
       "2                        Dua Lipa Featuring DaBaby              3         2   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              6         1   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              4         1   \n",
       "..                                             ...            ...       ...   \n",
       "95                                   Lainey Wilson             93        93   \n",
       "96                                    Thomas Rhett             89        73   \n",
       "97                     Elle King & Miranda Lambert             92        79   \n",
       "98                             Lil Baby & Lil Durk              -        99   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             67        12   \n",
       "\n",
       "   Weeks on Board  \n",
       "0               3  \n",
       "1               4  \n",
       "2              36  \n",
       "3              12  \n",
       "4              14  \n",
       "..            ...  \n",
       "95              4  \n",
       "96              6  \n",
       "97              7  \n",
       "98              1  \n",
       "99              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframes\n",
    "Top_100_songs = pd.DataFrame({\"Song Name\" : song_name ,\"Artist Name\": artist_name,\"Last week Rank\": last_week_rank,\n",
    "                              \"Peak Rank\" : peak_rank,\"Weeks on Board\" : weeks_on_board})\n",
    "Top_100_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "    A) Name\n",
    "\n",
    "    B) Designation\n",
    "\n",
    "    C) Company\n",
    "\n",
    "    D) Skills they hire for\n",
    "\n",
    "    E) Location\n",
    "\n",
    "    Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_naukari = \"https://www.naukri.com/\"\n",
    "driver.get(url_naukari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the link of recruiters option from the web page using xpath\n",
    "recruiters_link = driver.find_element_by_xpath(\"//ul[@class= 'midSec menu']//li[2]//a[@title = 'Search Recruiters']\").get_attribute('href')\n",
    "#now using link to get to the page\n",
    "driver.get(recruiters_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now extracting elements of search bar and search button\n",
    "search_bar = driver.find_element_by_xpath(\"//input[@class= 'sugInp']\")\n",
    "search_button = driver.find_element_by_xpath(\"//button[@class = 'fl qsbSrch blueBtn']\")\n",
    "\n",
    "#now we'll pass the input kes as \"Data science\" and click the search button\n",
    "search_bar.send_keys(\"Data Science\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list of all the desired features\n",
    "name = []\n",
    "designation = []\n",
    "company = []\n",
    "skills_hire = []\n",
    "location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    " #importing name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class = 'fl ellipsis']\"):\n",
    "        name.append(i.text)     #storing name in the list\n",
    "except NoSuchElementException:\n",
    "    name.append('-')\n",
    "\n",
    "\n",
    "\n",
    " #importing skills hire for using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class = 'hireSec highlightable']\"):\n",
    "        skills_hire.append(i.text)     #storing skill the hire in the list\n",
    "except NoSuchElementException:\n",
    "    skills_hire.append('-')\n",
    "\n",
    " #importing disgnation they hire for using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class = 'ellipsis clr']\"):\n",
    "        designation.append(i.text)     #storing designation  for in the list\n",
    "except NoSuchElementException:\n",
    "    designation.append('-')    \n",
    "    \n",
    " #importing location using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//p//span//small[@class = 'ellipsis']\"):\n",
    "        location.append(i.text)     #storing location in the list\n",
    "except NoSuchElementException:\n",
    "    location.append('-')\n",
    "\n",
    "\n",
    "    \n",
    "#importing company name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class = 'highlightable']//a[2]\"):\n",
    "        company.append(i.text)     #storing company in the list\n",
    "except NoSuchElementException:\n",
    "    company.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills they hire for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Python, Artificial Intelligence, Machine Learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Java, Python, Angularjs, Software Testing, Mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Indore</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>MYSORE</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td></td>\n",
       "      <td>consulting, Education Counseling, Educational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sunny Sharma</td>\n",
       "      <td>Managing Director - HR</td>\n",
       "      <td>Western Service Providers</td>\n",
       "      <td></td>\n",
       "      <td>Software Professionals, Engineering, Technical...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                    Ruchi Dhote   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                   Kapil Devang   \n",
       "16                                  Manisha Yadav   \n",
       "17                                    Riya Rajesh   \n",
       "18                           Rashmi Bhattacharjee   \n",
       "19                                  Faizan Kareem   \n",
       "20                                 Rithika dadwal   \n",
       "21                                  Azahar Shaikh   \n",
       "22                             Sandhya Khandagale   \n",
       "23                                      Shaun Rao   \n",
       "24                                          Manas   \n",
       "25                                          kumar   \n",
       "26                                   Sunil Vedula   \n",
       "27                                    Rajat Kumar   \n",
       "28                                    Priya Khare   \n",
       "29                                Dhruv Dev Dubey   \n",
       "30                                      Jayanth N   \n",
       "31                                       SREEDHAR   \n",
       "32                              Radha Manivasagam   \n",
       "33                                  Prateek Kumar   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "48                                 Shailja Mishra   \n",
       "49                                   Sunny Sharma   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14                         HR Team Lead   \n",
       "15                           HR Manager   \n",
       "16                         HR Executive   \n",
       "17           Manager Talent Acquisition   \n",
       "18                              HR Head   \n",
       "19                           HR MANAGER   \n",
       "20                         HR Recruiter   \n",
       "21                    Company Recruiter   \n",
       "22                         HR Recruiter   \n",
       "23              Manager Human Resources   \n",
       "24              Lead Talent acquisition   \n",
       "25                           Proprietor   \n",
       "26                                  CEO   \n",
       "27                          Founder CEO   \n",
       "28                       Senior Manager   \n",
       "29             Company Recruitment Head   \n",
       "30                      Project Manager   \n",
       "31               Recruitment Consultant   \n",
       "32                         HR Executive   \n",
       "33                                 Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48                           HR Manager   \n",
       "49               Managing Director - HR   \n",
       "\n",
       "                                           Company                  Location  \\\n",
       "0                             Data Science Network                     Delhi   \n",
       "1                    Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad   \n",
       "2                         MARSIAN Technologies LLP                      Pune   \n",
       "3            Enerlytics Software Solutions Pvt Ltd                 Ahmedabad   \n",
       "4                                  LibraryXProject             UK - (london)   \n",
       "5       Apidel Technologies Division of Transpower         Vadodara / Baroda   \n",
       "6                                             IFMR                   Chennai   \n",
       "7                      Techvantage Systems Pvt Ltd                Trivandrum   \n",
       "8                       Weupskill- Live Wire India                    Indore   \n",
       "9                 CBL Data Science Private Limited     Bengaluru / Bangalore   \n",
       "10                              Innominds Software  Hyderabad / Secunderabad   \n",
       "11                                        MoneyTap     Bengaluru / Bangalore   \n",
       "12              QuantMagnum Technologies Pvt. Ltd.                    Mumbai   \n",
       "13                           Bristlecone India Ltd                      Pune   \n",
       "14                               SocialPrachar.com  Hyderabad / Secunderabad   \n",
       "15                                  BISP Solutions                    Bhopal   \n",
       "16                                        Easi Tax               Navi Mumbai   \n",
       "17                     Novelworx Digital Solutions                    Cochin   \n",
       "18         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...                     Delhi   \n",
       "19                   FirstTech Consaltants Pvt.Ltd  Hyderabad / Secunderabad   \n",
       "20                                Affine Analytics                      Pune   \n",
       "21                 NEAL ANALYTICS SERVICES PVT LTD                      Pune   \n",
       "22                 Compumatrice Multimedia Pvt Ltd                      Pune   \n",
       "23                              Exela Technologies                      Pune   \n",
       "24      Autumn Leaf Consulting Services Private...     Bengaluru / Bangalore   \n",
       "25                                         trainin     Bengaluru / Bangalore   \n",
       "26                            Nanoprecise Sci Corp                     Delhi   \n",
       "27                  R.S Consultancy &amp; Services     Bengaluru / Bangalore   \n",
       "28                          Independent Consultant     Bengaluru / Bangalore   \n",
       "29                                    Confidential           Mysoru / Mysore   \n",
       "30        Dollarbird Information Services Pvt, Ltd  Hyderabad / Secunderabad   \n",
       "31     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED     Bengaluru / Bangalore   \n",
       "32                                      Techcovery                     Noida   \n",
       "33                                         Trisect                 New Delhi   \n",
       "34                                 ASCO consulting                   Chennai   \n",
       "35                                         NY INST                   Aligarh   \n",
       "36  3D India Staffing Research &amp; Consulting...            Salt Lake City   \n",
       "37                                     O.C. Tanner                      Pune   \n",
       "38                                   Demand Matrix     Bengaluru / Bangalore   \n",
       "39                             MADHUSUDHAN SRIDHAR                    Mumbai   \n",
       "40                                  Suntech Global                    Indore   \n",
       "41                        Strategic Consulting Lab     Bengaluru / Bangalore   \n",
       "42                            Impel Labs Pvt. Ltd.                    MYSORE   \n",
       "43                                    MRP Advisers  Hyderabad / Secunderabad   \n",
       "44                   Saras Solutions India Pvt Ltd     Bengaluru / Bangalore   \n",
       "45                                     WildJasmine                    Mumbai   \n",
       "46                             LNT Private Limited                     Noida   \n",
       "47                                     Granular.ai                    Mumbai   \n",
       "48                               Certybox Pvt.Ltd.                             \n",
       "49                       Western Service Providers                             \n",
       "\n",
       "                                 Skills they hire for  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "11  Business Intelligence, Data Warehousing, Data ...  \n",
       "12  Office Administration, Hr Administration, tele...  \n",
       "13  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "14  Social Media, digital media maketing, seo, smm...  \n",
       "15     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "16  Telecalling, Client Interaction, Marketing, Re...  \n",
       "17                                       Data Science  \n",
       "18  Corporate Sales, Software Development, Softwar...  \n",
       "19  Data Analytics, Data Science, Machine Learning...  \n",
       "20  Data Science, Machine Learning, Python, R, Dee...  \n",
       "21  Data Science, Artificial Intelligence, Machine...  \n",
       "22  Big Data, Data Science, Artificial Intelligenc...  \n",
       "23  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
       "24  Software Architecture, Vp Engineering, Product...  \n",
       "25  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
       "26  Signal Processing, Machine Learning, Neural Ne...  \n",
       "27  Web Technologies, Project Management, Software...  \n",
       "28  Data Science, Artificial Intelligence, analyti...  \n",
       "29  Server Administartion, Verilog, Vhdl, Digital ...  \n",
       "30  Data Analytics, Managed Services, Team Leading...  \n",
       "31  Data Science, Machine Learning, Big Data Analy...  \n",
       "32  Python, Artificial Intelligence, Machine Learn...  \n",
       "33  Java, Python, Angularjs, Software Testing, Mac...  \n",
       "34  Machine Learning, Artificial Intelligence, Dat...  \n",
       "35  C, C++, Artificial Intelligence, Python, Php, ...  \n",
       "36  Relationship Management, Retail Sales, Private...  \n",
       "37                 Data Science, Software Engineering  \n",
       "38  Data Science, Big Data Analytics, Digital Mark...  \n",
       "39                  Data Science, Recruitment, Salary  \n",
       "40  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
       "41  Software Development, Business Intelligence, B...  \n",
       "42                   Data Science, Node.js, Angularjs  \n",
       "43  Data Science, Media Marketing, Resource Planni...  \n",
       "44  Data Analysis, Learning, Data Science, Compute...  \n",
       "45  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
       "46  Software Development, Core Java, Unit Testing,...  \n",
       "47  Machine Learning, Data Science, Product Manage...  \n",
       "48  consulting, Education Counseling, Educational ...  \n",
       "49  Software Professionals, Engineering, Technical...  "
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frames\n",
    "Data_Science_Recruiter = pd.DataFrame({\"Name\" : name , \"Designation\" :designation,\"Company\": company,\"Location\": location,\n",
    "                                        \"Skills they hire for\" : skills_hire})\n",
    "Data_Science_Recruiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_book = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(url_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the mentioned details.\n",
    "book_name = []\n",
    "author_name = []\n",
    "volumes_sold = []\n",
    "publisher = []\n",
    "genre = []\n",
    "\n",
    "\n",
    "\n",
    "#first extracting book name from the page\n",
    "book_name1 = driver.find_elements_by_xpath(\"//table[@class = 'in-article sortable']//tbody//tr//td[2]\")\n",
    "for i in book_name1:\n",
    "    book_name.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting aunthor name  from the page\n",
    "author_name1 = driver.find_elements_by_xpath(\"//table[@class = 'in-article sortable']//tbody//tr//td[3]\")\n",
    "for i in author_name1:\n",
    "    author_name.append(i.text)  #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting volume sold detail from the page\n",
    "volume_sold1 = driver.find_elements_by_xpath(\"//table[@class = 'in-article sortable']//tbody//tr//td[4]\")\n",
    "for i in volume_sold1:\n",
    "    volumes_sold.append(i.text)    #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting publisher from the page\n",
    "publisher1 = driver.find_elements_by_xpath(\"//table[@class = 'in-article sortable']//tbody//tr//td[5]\")\n",
    "for i in publisher1:\n",
    "    publisher.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#extracting genre dates from the page\n",
    "genre1 = driver.find_elements_by_xpath(\"//table[@class = 'in-article sortable']//tbody//tr//td[6]\")\n",
    "for i in genre1:\n",
    "    genre.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#creating data frame\n",
    "Highest_selling_novel = pd.DataFrame({\"Book Name\" : book_name, \"Author Name\" : author_name,\"Volumes Sold\": volumes_sold,\n",
    "                              \"Publisher\":publisher,\n",
    "                             \"Genre\":genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highest_selling_novel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_imdb = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the mentioned details.\n",
    "Name = []\n",
    "year_span = []\n",
    "Genre = []\n",
    "run_time = []\n",
    "Ratings = []\n",
    "votes =[]\n",
    "\n",
    "\n",
    "#first extracting name of tv show from the page\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class = 'lister-item-header']//a\"):\n",
    "    Name.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting year span  from the page\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class = 'lister-item-header']//span[@class ='lister-item-year text-muted unbold']\"):\n",
    "    year_span.append(i.text)  #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting Genre detail from the page\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class ='genre']\"):\n",
    "    Genre.append(i.text)    #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting Run time from the page\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class ='runtime']\"):\n",
    "    run_time.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "    \n",
    "#extracting Ratings from the page\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class = 'ipl-rating-star small']//span[@class ='ipl-rating-star__rating']\"):\n",
    "    Ratings.append(i.text)   #storing it in the list\n",
    "\n",
    "    \n",
    "\n",
    "#extracting Votes dates from the page\n",
    "for i in driver.find_elements_by_xpath(\"//span[@name ='nv']\"):\n",
    "    votes.append(i.text)   #storing it in the list    \n",
    "    \n",
    "    \n",
    "    \n",
    "#creating data frame\n",
    "IMDB_TV_SHOWS = pd.DataFrame({\"Name\" : Name, \"Year Span\" : year_span,\"Genre\": Genre,\n",
    "                              \"Run Time\":run_time, \"Rating\" : Ratings,\n",
    "                             \"Votes\":votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,823,541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>864,019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Rating      Votes  \n",
       "0    57 min    9.3  1,823,541  \n",
       "1    51 min    8.7    864,019  \n",
       "2    44 min    8.2    874,576  \n",
       "3    60 min    7.6    262,713  \n",
       "4    43 min    7.6    224,072  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.5     44,581  \n",
       "96   50 min    7.8     55,079  \n",
       "97   42 min      8    167,786  \n",
       "98   45 min    7.1     34,892  \n",
       "99  572 min    8.6    191,470  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_TV_SHOWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Number 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating google chrome drivers instance and then passing the url to extract information from.\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url_uci = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url_uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting link to show all dataset page using xpath\n",
    "all_repository_link = driver.find_element_by_xpath(\"//table[1]//tbody//tr//td[2]//span[2]//a\").get_attribute('href')\n",
    "#now getting to the page\n",
    "driver.get(all_repository_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://archive.ics.uci.edu/ml/datasets.php'"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_repository_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(all_repository_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the mentioned details.\n",
    "\n",
    "names = []\n",
    "types = []\n",
    "task = []\n",
    "attribute = []\n",
    "instances =[]\n",
    "attribute_number = []\n",
    "year = []\n",
    "\n",
    "\n",
    "#importing Repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//table//tbody//td[2]//a\"):\n",
    "        names.append(i.text)     #storing Repository name in the list\n",
    "except NoSuchElementException:\n",
    "    names.append('-')\n",
    "\n",
    "    \n",
    "#importing Data types of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]/p\"):\n",
    "        types.append(i.text)     #storing data types in the list\n",
    "except NoSuchElementException:\n",
    "    types.append('-')\n",
    "\n",
    "    \n",
    "#importing task of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//tbody//td[3]//p[@class = 'normal']\"):\n",
    "        task.append(i.text)     #storing task in the list\n",
    "except NoSuchElementException:\n",
    "    task.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#importing Atrribute of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//tbody//td[4]//p[@class = 'normal']\"):\n",
    "        attribute.append(i.text)     #storing attribute in the list\n",
    "except NoSuchElementException:\n",
    "    attribute.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "#importing No. of instances of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//tbody//td[5]//p[@class = 'normal']\"):\n",
    "        instances.append(i.text)     #storing no. of instances in the list\n",
    "except NoSuchElementException:\n",
    "    instances.append('-')\n",
    "    \n",
    "    \n",
    "    \n",
    "#importing number of attributes of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//tbody//td[6]//p[@class = 'normal']\"):\n",
    "        attribute_number.append(i.text)     #storing no. of attributes in the list\n",
    "except NoSuchElementException:\n",
    "    attribute_number.append('-')\n",
    "    \n",
    "    \n",
    "#importing year of the repository name using the xpath\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[ @border = '1']//tbody//td[7]//p[@class = 'normal']\"):\n",
    "        year.append(i.text)     #storing year in the list\n",
    "except NoSuchElementException:\n",
    "    year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DataFrames\n",
    "Uci_repositiory_info = pd.DataFrame({\"Dataset name\" : names, \"Data type\" : types,\"Task\": task,\"Attribute type\" :attribute,\n",
    "                                    \"No of instances\":instances,\"No of attribute\" : attribute_number,\"Year\" :year })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset name      Data type                  Task  \\\n",
       "0                             Abalone  Multivariate        Classification    \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "4                          Arrhythmia  Multivariate        Classification    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute type No of instances No of attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "583                                       12684              23   2020   \n",
       "584                        Real              48             321   2020   \n",
       "585                        Real             731            1068   2021   \n",
       "586                        Real             731            1068   2021   \n",
       "587                        Real             557               5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uci_repositiory_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
